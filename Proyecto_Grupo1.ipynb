{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cca63ca",
   "metadata": {},
   "source": [
    "<img src='properati.png' align=\"center\" alt=\"drawing\" width=\"800\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a6ea8",
   "metadata": {},
   "source": [
    "### Grupo 1: *Natali Ferron, Daniela Ichinose, Andres Legorburu, Federico Idoeta, Gonzalo Garcia*\n",
    "---\n",
    "### Flujo de trabajo \n",
    "<a name=\"top\"></a>\n",
    "* [1. Analisis de la base de datos](#inicial)\n",
    "* [2. Extracción de informacion de la columna description](#extraccion)\n",
    "* [3. Limpieza de los datos](#limpieza)\n",
    ">[3a.Limpieza de place_name](#limpiezaA)</br>\n",
    ">[3b.Limpieza de surface](#limpiezaB)</br>\n",
    ">[3c.Limpieza de price](#limpiezaC)</br>\n",
    "\n",
    "* [4. Imputacion de los datos faltantes](#imputacion)\n",
    ">[4a.Imputación de superficie](#impA)</br>\n",
    ">[4b.Imputación de Ambientes](#impB)</br>\n",
    ">[4c.Imputación de precio](#impC)</br>\n",
    ">[4d.Operaciones adicionales](#impD)</br>\n",
    ">[4e.Reimputación de valores](#impE)</br>\n",
    ">[4f.Eliminación de outliers en precio y precio por m2](#impF)</br>\n",
    ">[4g.Imputacion de las columnas latitud y longitud](#impG)\n",
    "\n",
    "* [5. Analisis descriptivo](#five) \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031ac070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f3282",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"inicial\"></a>\n",
    "## 1.Analisis de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ab6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de datos\n",
    "data = pd.read_csv('properatti.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "928c0ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null</th>\n",
       "      <th>ratio</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>floor</th>\n",
       "      <td>113321</td>\n",
       "      <td>0.93</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>106958</td>\n",
       "      <td>0.88</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>73830</td>\n",
       "      <td>0.61</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_usd_per_m2</th>\n",
       "      <td>52603</td>\n",
       "      <td>0.43</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat-lon</th>\n",
       "      <td>51550</td>\n",
       "      <td>0.43</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>51550</td>\n",
       "      <td>0.43</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon</th>\n",
       "      <td>51550</td>\n",
       "      <td>0.43</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <td>39328</td>\n",
       "      <td>0.32</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_per_m2</th>\n",
       "      <td>33562</td>\n",
       "      <td>0.28</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>20411</td>\n",
       "      <td>0.17</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_aprox_local_currency</th>\n",
       "      <td>20410</td>\n",
       "      <td>0.17</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>20410</td>\n",
       "      <td>0.17</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <td>20410</td>\n",
       "      <td>0.17</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <td>19907</td>\n",
       "      <td>0.16</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geonames_id</th>\n",
       "      <td>18717</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_thumbnail</th>\n",
       "      <td>3112</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_name</th>\n",
       "      <td>23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operation</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_with_parent_names</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>properati_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              null  ratio  percent\n",
       "floor                       113321   0.93     93.0\n",
       "expenses                    106958   0.88     88.0\n",
       "rooms                        73830   0.61     61.0\n",
       "price_usd_per_m2             52603   0.43     43.0\n",
       "lat-lon                      51550   0.43     43.0\n",
       "lat                          51550   0.43     43.0\n",
       "lon                          51550   0.43     43.0\n",
       "surface_total_in_m2          39328   0.32     32.0\n",
       "price_per_m2                 33562   0.28     28.0\n",
       "currency                     20411   0.17     17.0\n",
       "price_aprox_local_currency   20410   0.17     17.0\n",
       "price                        20410   0.17     17.0\n",
       "price_aprox_usd              20410   0.17     17.0\n",
       "surface_covered_in_m2        19907   0.16     16.0\n",
       "geonames_id                  18717   0.15     15.0\n",
       "image_thumbnail               3112   0.03      3.0\n",
       "place_name                      23   0.00      0.0\n",
       "description                      2   0.00      0.0\n",
       "operation                        0   0.00      0.0\n",
       "state_name                       0   0.00      0.0\n",
       "country_name                     0   0.00      0.0\n",
       "place_with_parent_names          0   0.00      0.0\n",
       "property_type                    0   0.00      0.0\n",
       "properati_url                    0   0.00      0.0\n",
       "title                            0   0.00      0.0\n",
       "Unnamed: 0                       0   0.00      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isnull_explorer(df):\n",
    "    # explora cada columna del DF y genera un DF con columna, nulos, ratio y percent\n",
    "    total_values= df.shape[0]\n",
    "    result=dict()\n",
    "    for col in df.columns:\n",
    "        null= df[col].isnull().sum()\n",
    "        ratio = round(null/total_values,2)\n",
    "        percent = round(ratio * 100,2)\n",
    "        result[col]=(null,ratio, percent)\n",
    "    result_df = pd.DataFrame.from_dict(result, orient='index')\n",
    "    result_df.rename(columns={0:'null',1:'ratio',2:'percent'}, inplace=True)\n",
    "    return  result_df.sort_values(by='null', ascending=False)\n",
    "isnull_explorer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3adc948f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bº Residencial San Roque.-'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.title[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630de29",
   "metadata": {},
   "source": [
    "### *Del análisis inicial se destaca:*\n",
    "1. Alto porcentaje de valores nulos en las columnas floor y expenses, las cuales se descartan para el análisis.\n",
    "2. Bajo porcentaje de nulos en place_name con respecto a latitud y longitud, se decide optimizar place_name con la información de la columna place_with_parent_names y utilizar el resultado como fuente de localización de las propiedades.\n",
    "3. La columna price_aprox_usd se utilizará como referencia para precios.\n",
    "4. La columna surface_total se utilizará como referencia para superficie por poseer mejores coeficientes de correlacion, con respecto a precio (que surface_covered).\n",
    "5. Se observa que la distribucion de precio y superficie tiene sesgo hacia la izquierda, por lo que se tomará la mediana como parametro de imputación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef690109",
   "metadata": {},
   "source": [
    "[Subir](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b50ffb",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"extraccion\"></a>\n",
    "## 2. Extracción de información de la columna description \n",
    "#### *Se realizó una exploración en busca de las palabras más frecuentes (más de 3000), de las mismas se seleccionaron aquellas relacionadas con la descripción de la propiedad, se agruparon por categorías y fueron utilizadas para extraer esa información con regex.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "406e1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con los nombres de las columnas (categorías) y sus correspondientes regex\n",
    "regexA={'price1':'(?P<dolar>\\d+\\.?\\d+)(\\s?(us|usd|u\\$|u\\$d|u\\$s))',\n",
    "           'price2':'(us|usd|u\\$|u\\$d|u\\$s)\\s?(?P<dolar>\\d+\\.?\\d+)\\s?',\n",
    "           'surface':'(\\d+)(\\s?m|m2|mt|mts)',\n",
    "           'ambientes':'(?P<ambientes>\\d)(\\s?amb)',\n",
    "           'rooms':'(?P<dormitorios>\\d)(\\s?(dorm|habit))'}\n",
    "regexB= {'monoambiente':'monoamb',\n",
    "           'contrafrente':'contrafrente',\n",
    "           'cochera':'(coch|gara)',\n",
    "           'amenities':'(ameniti|solar|segur|calder|calefac|radian|pileta|pisc)',\n",
    "           'esp_exterior':'(balc|jard|terra|patio|galer|parril|quinch)',\n",
    "           'dependencia':'dependen',\n",
    "           'living':'(livi|comed)',\n",
    "           'mas_1banio':'(baño|baños|toilet)',\n",
    "           'store':'local',\n",
    "           'departamento':'(depart|depto|torr)',\n",
    "           'casa':'(chale|casa|duplex)',\n",
    "           'estrenar':'estren'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recibe el DF y devuelve un nuevo df con las columnas de cada nivel de regex \n",
    "def extraction_description(data, regexA, regexB):\n",
    "    df_result=pd.DataFrame()\n",
    "    final=list()\n",
    "    serie_description= data.loc[:,'description']\n",
    "    for index in range(len(serie_description)):\n",
    "        result=dict()\n",
    "        result['index_control']=index\n",
    "        text=serie_description.iloc[index]\n",
    "        if type(text)==str:\n",
    "            text=text.lower()\n",
    "            for key, value in regexA.items():\n",
    "                exist= re.search(value,text)\n",
    "                if exist==None:\n",
    "                    result[key]=0\n",
    "                else:\n",
    "                    if key == 'price2':\n",
    "                        dolars=exist.group(2)\n",
    "                        dolars=float(dolars)*1000\n",
    "                        result[key]=dolars\n",
    "                    elif key=='price1':\n",
    "                        dolars=exist.group(1)\n",
    "                        dolars=float(dolars)*1000\n",
    "                        result[key]=dolars\n",
    "                    elif key=='surface'or key=='ambientes'or key=='rooms':\n",
    "                        others=exist.group(1)\n",
    "                        result[key]=float(others)\n",
    "                       \n",
    "            for key2,value2 in regexB.items():\n",
    "                if re.search(value2,text)==None:\n",
    "                    result[key2]=0\n",
    "                else:\n",
    "                    result[key2]=1\n",
    "            final.append(result)\n",
    "        else:\n",
    "            for key, value in regexA.items():\n",
    "                result[key]=0\n",
    "            for key2,value2 in regexB.items():\n",
    "                result[key2]=0\n",
    "            final.append(result)\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "# Generacion del dataframe a partir del campo description\n",
    "df_regex=extraction_description(data,regexA,regexB) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a50714",
   "metadata": {},
   "source": [
    "#### *Limpieza del dataframe generado al aplicar expresiones regulares a la columna description*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unifica price en una sola columna\n",
    "df_regex['price_rgx']=df_regex.apply(lambda x: x.price2 if x.price2>=x.price1 else x.price1, axis=1)  \n",
    "\n",
    "# Extraccion de los ambientes encontrados, de ser nulos se suman habitaciones, dependencia y living\n",
    "def logical_rooms(row):\n",
    "    if row.ambientes!=0:\n",
    "        return row.ambientes\n",
    "    elif row['monoambiente']==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return row.rooms+row.dependencia+row.living\n",
    "\n",
    "df_regex['rooms_rgx']= df_regex.apply(logical_rooms, axis=1)\n",
    "\n",
    "# Se eliminan los valores de m2 menores que 18 y mayores que 5000\n",
    "antes=(df_regex.surface>0).sum()\n",
    "df_regex['surface_rgx']=df_regex.surface.apply(lambda x: x if x>18 and x<5000 else np.NaN)\n",
    "\n",
    "# Se eliminan las columnas que no son necesarias\n",
    "df_regex.drop(columns=['index_control', 'price1', 'price2', 'surface', 'ambientes', 'rooms','monoambiente','dependencia', 'living'], inplace=True)\n",
    "\n",
    "print(f'Hay {(df_regex.price_rgx>0).sum()} valores en price_rgx')\n",
    "print(f'Hay {(df_regex.rooms_rgx>0).sum()} valores para rooms_rgx')\n",
    "print(f'Habia {antes} valores de m2, luego de aplicar el filtro (>18m2 y<5000m2) quedan {(df_regex.surface_rgx.notnull()).sum()} valores en surface_rgx')\n",
    "\n",
    "columnas ={'contrafrente':'al contrafrente', 'cochera':'con cochera', 'amenities':'con amenities(incluye pileta)',\\\n",
    "           'esp_exterior':'con espacios al exterior', 'mas_1banio':'con mas de 1 baño', 'estrenar':'a estrenar'}\n",
    "for col,text in columnas.items():\n",
    "    print(f'propiedades {text}: {df_regex[col].sum()}')   \n",
    "\n",
    "    # Se une el dataframe con la informacion del campo description a la base original con un merge\n",
    "dataClean=pd.merge(data,df_regex, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ed44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc8376",
   "metadata": {},
   "source": [
    "#### *Se exploró completar los valores nulos en precio (price_rgx), superficie (surface_rgx) y ambientes (rooms_rgx) con la información obtenida desde description pero se detectó que no aportan nuevos datos.*\n",
    "(en instancias posteriores se analizarán cada uno de los campos mencionados)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa103b",
   "metadata": {},
   "source": [
    "[Subir](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7926f",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"limpieza\"></a>\n",
    "## 3. Limpieza de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76270d4c",
   "metadata": {},
   "source": [
    "<a name=\"limpiezaA\"></a>\n",
    "### *3a. Se quitan duplicados y columnas sin información (fc quitar_columnas), limpieza de place_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se exploran y borran las filas dupicadas\n",
    "def quitar_duplicados(data):\n",
    "    data.drop_duplicates(['operation', 'property_type', 'place_name',\n",
    "       'place_with_parent_names', 'country_name', 'state_name', 'geonames_id',\n",
    "       'lat-lon', 'lat', 'lon', 'price', 'currency',\n",
    "       'price_aprox_local_currency', 'price_aprox_usd', 'surface_total_in_m2',\n",
    "       'surface_covered_in_m2', 'price_usd_per_m2', 'price_per_m2', 'floor',\n",
    "       'expenses', 'description', 'title',\n",
    "       'image_thumbnail'], keep='first', inplace = True)\n",
    "    data.reset_index(inplace = True, drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se explora la columna place_name y se completa con place_with_parent_names para que quede la localidad en place name\n",
    "def limpiar_place_name(data):\n",
    "\n",
    "    #Creo un DataFrame de las columnas de place\n",
    "    place = data.loc[:,['place_name','place_with_parent_names']]\n",
    "    \n",
    "    #Imprimo los null de place_name antes del cambio\n",
    "    #print('Cantidad de null en place_name:', data.place_name.isnull().sum())\n",
    "    \n",
    "    #Todos los valores NaN en place_name corresponde a Tigre:\n",
    "    #print(place[place.place_name.isnull()])\n",
    "    data['place_name']= place['place_name'].fillna(\"Tigre\")\n",
    "    \n",
    "    #Imprimo los null de place_name despues del cambio\n",
    "    #print('Cantidad de null en place_name:', data.place_name.isnull().sum())\n",
    "\n",
    "    #Patron para separar datos de place_with_parent_names\n",
    "    pattern_place_name= '\\|'\n",
    "    regex_place_name = re.compile(pattern_place_name)\n",
    "    resultado = place.place_with_parent_names.apply(lambda x: x if x is np.NaN else regex_place_name.split(x))\n",
    "    # Creo una lista donde acumulo los resultados de la columna 3 (correspondiente a place_name)\n",
    "    resultado2 =[]\n",
    "    for y in range(len(resultado)):\n",
    "#        if resultado[y][3] != '':\n",
    "        resultado2.append(resultado[y][3])\n",
    "#        else:\n",
    "#            resultado2.append(resultado[y][2])\n",
    "            \n",
    "    #Asigno los resultados de resultados2 a la columna place_name\n",
    "    place['place_name'] = resultado2\n",
    "    \n",
    "    #A los campos vacios los completo con NaN\n",
    "    for j in range(len(place.place_name)):\n",
    "        if place.loc[j,'place_name']==\"\":\n",
    "            place.loc[j,'place_name']=np.NaN\n",
    "    \n",
    "    #Asigno los resultados a la columna place_name del df\n",
    "    data['place_name'] = place['place_name']\n",
    "    data = data[data.place_name.notnull()]\n",
    "    data.reset_index(inplace = True, drop=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d84cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se quitan las columnas que no contienen informacion relevante\n",
    "def quitar_columnas(data):\n",
    "    data.drop(['Unnamed: 0', 'operation', 'country_name',  'geonames_id',  'lat-lon',  'price',  'currency', \n",
    "               'price_aprox_local_currency',  'price_usd_per_m2', 'price_per_m2', 'floor', 'properati_url', \n",
    "               'expenses','image_thumbnail', 'price_rgx', 'rooms_rgx','store', 'departamento', 'casa',\n",
    "               'surface_rgx'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quito duplicados\n",
    "dataClean= quitar_duplicados(dataClean) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9da70",
   "metadata": {},
   "source": [
    "#### *Se comprueba que no hay duplicados en el dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71627d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean.duplicated(['operation', 'property_type', 'place_name',\n",
    "       'place_with_parent_names', 'country_name', 'state_name', 'geonames_id',\n",
    "       'lat-lon', 'lat', 'lon', 'price', 'currency',\n",
    "       'price_aprox_local_currency', 'price_aprox_usd', 'surface_total_in_m2',\n",
    "       'surface_covered_in_m2', 'price_usd_per_m2', 'price_per_m2', 'floor',\n",
    "       'rooms', 'expenses', 'description', 'title',\n",
    "       'image_thumbnail']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#asigno correctamente la columna place_name y elimino los place_names que no se pueden asignar (ej: Cba, Capital Federal)\n",
    "dataClean = limpiar_place_name(dataClean) \n",
    "# se quitan las columnas\n",
    "dataClean = quitar_columnas(dataClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8959b",
   "metadata": {},
   "source": [
    "#### *Se comprueba que no hay valores nulos en place_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean.place_name.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamaño del dataset original: 121220 propiedades\n",
    "dataClean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65e1eb",
   "metadata": {},
   "source": [
    "<a name=\"limpiezaB\"></a>\n",
    "### *3b. Limpieza de surface*\n",
    "####  *Se observan valores de superficie muy bajos (incluso iguales a 0). Se decide la estrategia de imputarlos con los valores mínimos legales para una vivienda (18 m2) y para un local (6 m2).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_data_00(data, m2store, m2other):\n",
    "    #En esta función asigné a una columna nueva el valor de la \"superficie total\" para poder trabajar -> \"superficie_total_in_m2_CLEAN\"\n",
    "    #Verifico que la superficie total sea el mayor valor entre total y cubierta y que si están al revés, use la mayor.    \n",
    "    data['surface_total_in_m2_CLEAN'] = np.where((data.surface_total_in_m2<=data.surface_covered_in_m2), data.surface_covered_in_m2, data.surface_total_in_m2)\n",
    "\n",
    "    # reemplazo todos los datos menores a Xm2 por el valor mínimo posible  \n",
    "    def replace_for(data, store, other):\n",
    "        if data.property_type=='store' and data.surface_total_in_m2_CLEAN<store:\n",
    "            return store\n",
    "        elif data.surface_total_in_m2_CLEAN<other:\n",
    "            return other\n",
    "        else:\n",
    "            return data.surface_total_in_m2_CLEAN\n",
    "    data['surface_total_in_m2_CLEAN']= data.apply(replace_for,args=(m2store,m2other),axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddab9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica el filtro de superficie con los valores de  6m2 para store y 18m2 para el resto de los tipos de propiedad\n",
    "dataClean = surface_data_00(dataClean, 6, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a6b17",
   "metadata": {},
   "source": [
    "#### *Se clasifican a las propiedades de  mas de 5000m2 en una nueva categoría dentro de property_type:\"oversized\" ya que en su mayoría son naves industriales, fábricas, campos, etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d396c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversized(data, limit):\n",
    "    for i in range(len(data)):\n",
    "        if data.surface_total_in_m2_CLEAN[i]>limit:\n",
    "            data.property_type[i]='oversized'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327dab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica la clasificacion utilizando el limite de 5000 m2\n",
    "dataClean=oversized(dataClean, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a062d00",
   "metadata": {},
   "source": [
    "#### *Se decidió eliminar las filas que corresponden a propiedades agrupadas por place_name con menos de 10 propiedades ya consideramos que no serían representativos para realizar imputaciones posteriores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74857ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = dataClean[dataClean.groupby(['state_name','place_name'])['place_name'].transform('count').ge(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a76790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamaño del dataset original: 121220 propiedades\n",
    "dataClean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf4f89",
   "metadata": {},
   "source": [
    "<a name=\"limpiezaC\"></a>\n",
    "### *3c. Limpieza de price*\n",
    "#### *Se detectaron precios en dólares muy bajos que se consideran errores de carga. A la vez existen valores extremedamente elevados y de muy pocas propiedades que se sospecha tambien puedan ser errores de carga. Se decidió la estrategia de reemplazarlos por NaN con valores de corte tomados en cuenta a partir de la información disponible en el mercado.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2203625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones que detecta los precios muy bajos y muy altos que se consideran errores de carga y los reemplaza con NaN\n",
    "def price_too_low(data, price):\n",
    "    data['price_aprox_usd']=data.price_aprox_usd.apply(lambda x: x if x>=price else np.NaN)\n",
    "    return data\n",
    "def overpriced(data, limit):  \n",
    "    data['price_aprox_usd']=data.price_aprox_usd.apply(lambda x: x if x<=limit else np.NaN)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c74059",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean= price_too_low(dataClean, 20000)\n",
    "dataClean=overpriced(dataClean,3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af93ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de registros nulos que quedaron al final de la limpieza por columna\n",
    "print('Nulos en price: ', dataClean.price_aprox_usd.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd6151",
   "metadata": {},
   "source": [
    "[Subir](#top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b035f84d",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"imputacion\"></a>\n",
    "## 4. Imputación de datos faltantes en superficie, ambientes y precio.\n",
    "<a name=\"impA\"></a>\n",
    "### 4.a Imputación de Superficie\n",
    "\n",
    "#### 4.a.1. Imputación Superficie: 1er nivel\n",
    "##### *Se decidió la estrategia de imputar las superficies faltantes usando la mediana agrupada por lugar, tipos de propiedades y subgrupos de precios (5 bines).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputa con la mediana de la superficie total, agrupando por place_name, property_type y bin_price\n",
    "def imp_superficie(data, bines): \n",
    "    \n",
    "    data['bin_price'] = pd.qcut(data.price_aprox_usd, bines).astype('category')\n",
    "    fill_values = data.groupby(['place_name','property_type','bin_price'])['surface_total_in_m2_CLEAN'].median()\n",
    "\n",
    "    \n",
    "    fill_values_df = pd.DataFrame(fill_values)\n",
    "    fill_values_df.reset_index(inplace = True)\n",
    "    \n",
    "    data = data.merge(fill_values, on = ['place_name','property_type', 'bin_price'], suffixes = (\"\", \"_median\"), how = 'left')\n",
    "    data.surface_total_in_m2_CLEAN.fillna(data.surface_total_in_m2_CLEAN_median, inplace = True)\n",
    "\n",
    "    data.drop('surface_total_in_m2_CLEAN_median', axis=1, inplace=True)\n",
    "    \n",
    "    print('Nulos en surface_total_in_m2_CLEAN: ', data.surface_total_in_m2_CLEAN.isnull().sum())\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = imp_superficie(dataClean, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b692088",
   "metadata": {},
   "source": [
    "#### 4.a.2. Imputación Superficie: 2do nivel\n",
    "##### *Luego se realiza una segunda imputación agrupando únicamente por lugar y tipo de propiedad para los datos de precios faltantes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de317c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputa con la mediana de la superficie total, agrupando por place_name y property_type\n",
    "def imp_superficie_bis(data): \n",
    "    fill_values = data.groupby(['place_name','property_type'])['surface_total_in_m2_CLEAN'].median()\n",
    "\n",
    "    fill_values_df = pd.DataFrame(fill_values)\n",
    "    fill_values_df.reset_index(inplace = True)\n",
    "    \n",
    "    data = data.merge(fill_values, on = ['place_name','property_type'], suffixes = (\"\", \"_median\"), how = 'left')\n",
    "    data.surface_total_in_m2_CLEAN.fillna(data.surface_total_in_m2_CLEAN_median, inplace = True)\n",
    "\n",
    "    data.drop('surface_total_in_m2_CLEAN_median', axis=1, inplace=True)\n",
    "    \n",
    "    print('Nulos en surface_total_in_m2_CLEAN: ', data.surface_total_in_m2_CLEAN.isnull().sum())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b728d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = imp_superficie_bis(dataClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32285fa9",
   "metadata": {},
   "source": [
    "<a name=\"impB\"></a>\n",
    "### 4.b. Imputación de ambientes\n",
    "#### 4.b.1. Imputación ambientes: 1er nivel\n",
    "##### *Se exploraron las columnas title y description utilizando regex para extraer la cantidad de ambientes por propiedad.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd33161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se extrae la informacion de la cantidad de ambientes en la columna descripcion y title utilizando regex.\n",
    "def regex_rooms(data):\n",
    "\n",
    "    patron = '(\\d)( )?(?i)(ambiente|amb)'\n",
    "    regex = re.compile(patron)\n",
    "\n",
    "    match = data.description.apply(lambda x: x if x is np.NaN else regex.search(x))\n",
    "    mask = match.notnull()\n",
    "    data.loc[mask, \"rooms\"] = match[mask].apply(lambda x: x if x is np.NaN else x.group(1))\n",
    "\n",
    "    match_01 = data.title.apply(lambda x: x if x is np.NaN else regex.search(x))\n",
    "    mask_01 = match_01.notnull()\n",
    "    data.loc[mask_01, \"rooms\"] = match_01[mask_01].apply(lambda x: x if x is np.NaN else x.group(1))\n",
    "\n",
    "    data.rooms = dataClean.rooms.astype('float64')\n",
    "    \n",
    "    patron_monoambiente = 'monoambiente'\n",
    "    regex = re.compile(patron_monoambiente, flags=re.IGNORECASE)\n",
    "\n",
    "    match = data.description.apply(lambda x: x if x is np.NaN else regex.search(x))\n",
    "    mask = match.notnull()\n",
    "    data.loc[mask, \"rooms\"] = match[mask].apply(lambda x: x if x is np.NaN else 1)\n",
    "\n",
    "    match_01 = data.title.apply(lambda x: x if x is np.NaN else regex.search(x))\n",
    "    mask_01 = match_01.notnull()\n",
    "    data.loc[mask_01, \"rooms\"] = match_01[mask_01].apply(lambda x: x if x is np.NaN else 1)\n",
    "    \n",
    "    data.rooms = dataClean.rooms.astype('float64')\n",
    "    print('Nulos en regex rooms: ', data.rooms.isnull().sum())\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reemplazan con NaN los valores de rooms mayores a 15\n",
    "def many_rooms(data, limit):  \n",
    "    data['rooms']=data.rooms.apply(lambda x: x if x<=limit else np.NaN)\n",
    "    print('Nulos en many rooms: ', data.rooms.isnull().sum())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a012a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=dataClean, y='rooms', x='property_type')\n",
    "plt.title('Distribución de rooms por property_type - Pre-limpieza');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = regex_rooms(dataClean)\n",
    "#Según lo analizado en el mercado es poco probable que una propiedad tenga más de 15 ambientes. \n",
    "dataClean = many_rooms(dataClean,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=dataClean, y='rooms', x='property_type')\n",
    "plt.title('Distribución de rooms por property_type - Post-limpieza');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec3293",
   "metadata": {},
   "source": [
    "#### 4.b.2. Imputación ambientes: 2do nivel. \n",
    "##### *Se decidió la estrategia de imputar los ambientes faltantes utilizando la mediana agrupada por lugar, tipos de propiedades y subgrupos de superficie (5 bines).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputa con la mediana del campo rooms, agrupando por place_name, property_type y bin_sup\n",
    "def imp_rooms(data, bines): \n",
    "    data['bin_sup'] = pd.qcut(data.surface_total_in_m2_CLEAN, bines).astype('category')\n",
    "    fill_values = data.groupby(['place_name', 'property_type', 'bin_sup']).rooms.median().round(0)\n",
    "    fill_values_df = pd.DataFrame(fill_values)\n",
    "    fill_values_df.reset_index(inplace = True)\n",
    "    data_2 = data.merge(fill_values_df, on = ['place_name', 'property_type', 'bin_sup'], suffixes = (\"\", \"_median\"), how = 'left')\n",
    "    data_2.rooms.fillna(data_2.rooms_median, inplace = True)\n",
    "    data_2.drop('rooms_median', axis=1, inplace=True)\n",
    "\n",
    "    print('Nulos en rooms: ', data_2.rooms.isnull().sum())\n",
    "\n",
    "    return data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e541e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = imp_rooms(dataClean, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90edee61",
   "metadata": {},
   "source": [
    "[Subir](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e98b3",
   "metadata": {},
   "source": [
    "<a name=\"impC\"></a>\n",
    "### 4.c. Imputación de precio\n",
    "##### Se realizan tres niveles de imputación con diferentes grados de agrupación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e5734",
   "metadata": {},
   "source": [
    "#### 4.c.1. Imputación de Precio: 1er nivel\n",
    "##### *Se decidió la estrategia de imputar los precios faltantes usando la mediana agrupada por lugar, tipos de propiedades, subgrupos de superficie (5 bines) y ambientes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50226a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputa con la mediana del precio total, agrupando por place_name, property_type, bin_sup y rooms.\n",
    "def imp_precio_rooms(data, bines): \n",
    "    data['bin_sup'] = pd.qcut(data.surface_total_in_m2_CLEAN, bines).astype('category')\n",
    "    fill_values = data.groupby(['place_name', 'property_type', 'bin_sup', 'rooms']).price_aprox_usd.median().round(2)\n",
    "\n",
    "    fill_values_df = pd.DataFrame(fill_values)\n",
    "    fill_values_df.reset_index(inplace = True)\n",
    "\n",
    "    data_2 = data.merge(fill_values_df, on = ['place_name', 'property_type', 'bin_sup', 'rooms'], suffixes = (\"\", \"_median\"), how = 'left')\n",
    "\n",
    "    data_2.price_aprox_usd.fillna(data_2.price_aprox_usd_median, inplace = True)\n",
    "\n",
    "    data_2.drop('price_aprox_usd_median', axis=1, inplace=True)\n",
    "\n",
    "    print('Nulos en price_aprox_usd: ', data_2.price_aprox_usd.isnull().sum())\n",
    "\n",
    "    return data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = imp_precio_rooms(dataClean,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac27247",
   "metadata": {},
   "source": [
    "#### 4.c.2. Imputación de Precio: 2do nivel\n",
    "##### *Luego para las propiedades que persisten sin datos de precio ni ambientes, se decide imputar agrupando por lugar, tipos de propiedades y subgrupos de superficie (5 bines).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3bd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputa con la mediana del precio total, agrupando por place_name, property_type y bin_sup\n",
    "def imp_precio(data, bines): \n",
    "    data['bin_sup'] = pd.qcut(data.surface_total_in_m2_CLEAN, bines).astype('category')\n",
    "   \n",
    "    fill_values = data.groupby(['place_name', 'property_type', 'bin_sup']).price_aprox_usd.median().round(2)\n",
    "    fill_values_df = pd.DataFrame(fill_values)\n",
    "    fill_values_df.reset_index(inplace = True)\n",
    "\n",
    "    data_2 = data.merge(fill_values_df, on = ['place_name', 'property_type', 'bin_sup'], suffixes = (\"\", \"_median\"), how = 'left')\n",
    "    data_2.price_aprox_usd.fillna(data_2.price_aprox_usd_median, inplace = True)\n",
    "    data_2.drop('price_aprox_usd_median', axis=1, inplace=True)\n",
    "\n",
    "    print('Nulos en price_aprox_usd: ', data_2.price_aprox_usd.isnull().sum())\n",
    "\n",
    "    return data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = imp_precio(dataClean,5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58633af",
   "metadata": {},
   "source": [
    "#### 4.c.3 Imputación de Precio: 3er nivel\n",
    "##### *Finalmente se realiza una tercera imputación de precios faltantes agrupando por lugar y tipos de propiedades*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputa con la mediana del precio, agrupando por place_name y property_type\n",
    "def imp_precio_bis(data): \n",
    "   \n",
    "    fill_values = data.groupby(['place_name', 'property_type']).price_aprox_usd.median().round(2)\n",
    "    fill_values_df = pd.DataFrame(fill_values)\n",
    "    fill_values_df.reset_index(inplace = True)\n",
    "\n",
    "    data_2 = data.merge(fill_values_df, on = ['place_name', 'property_type'], suffixes = (\"\", \"_median\"), how = 'left')\n",
    "    data_2.price_aprox_usd.fillna(data_2.price_aprox_usd_median, inplace = True)\n",
    "    data_2.drop('price_aprox_usd_median', axis=1, inplace=True)\n",
    "\n",
    "    print('Nulos en price_aprox_usd: ', data_2.price_aprox_usd.isnull().sum())\n",
    "\n",
    "    return data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = imp_precio_bis(dataClean) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5645ed8",
   "metadata": {},
   "source": [
    "[Subir](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321400f2",
   "metadata": {},
   "source": [
    "<a name=\"impD\"></a>\n",
    "### 4.d. Operaciones adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7ed48",
   "metadata": {},
   "source": [
    "#### *4.d.1 Se eliminan los nulos en superficie y precio que no se pudieron imputar por falta de datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab73ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_null_SupPrice(data):\n",
    "    data = data[(data.surface_total_in_m2_CLEAN.notnull())&(data.price_aprox_usd.notnull())]\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    return data\n",
    "dataClean = delete_null_SupPrice(dataClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd54f9f",
   "metadata": {},
   "source": [
    "#### *4.d.2 Se genera la columna precio por metro cuadrado*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean['price_m2_calc_supTotal'] = dataClean.price_aprox_usd / dataClean.surface_total_in_m2_CLEAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aac73f",
   "metadata": {},
   "source": [
    "#### *4.d.3 Se reemplazan por valores nulos los precios totales y por metro cuadrado de aquellas propiedades con precio por metro cuadrado mayor a:*\n",
    "* 10.000 u\\$d\\/m2 para AMBA</br>\n",
    "* 6.000 u\\$d\\/m2 para fuera de AMBA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e777c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_ppsqm(data, limitAMBA, limitOutAMBA):\n",
    "    for i in range(len(data)):\n",
    "        if (data.state_name[i]=='Capital Federal') or (data.state_name[i]=='Bs.As. G.B.A. Zona Sur') or (data.state_name[i]=='Bs.As. G.B.A. Zona Norte') or (data.state_name[i]=='Bs.As. G.B.A. Zona Oeste'):\n",
    "            if data.price_m2_calc_supTotal[i] > limitAMBA:\n",
    "                data.price_m2_calc_supTotal[i] = np.NaN\n",
    "                data.price_aprox_usd[i] = np.NaN\n",
    "        else:\n",
    "            if data.price_m2_calc_supTotal[i] > limitOutAMBA:\n",
    "                data.price_m2_calc_supTotal[i] = np.NaN\n",
    "                data.price_aprox_usd[i] = np.NaN\n",
    "    \n",
    "    print('Nulos en price_aprox_usd: ', data.price_aprox_usd.isnull().sum())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7273a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = high_ppsqm(dataClean, 10000, 6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32c9b9",
   "metadata": {},
   "source": [
    "[Subir](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7a362a",
   "metadata": {},
   "source": [
    "<a name=\"impE\"></a>\n",
    "### 4.e. Reimputación de valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5aa522",
   "metadata": {},
   "source": [
    "##### *Se vuelven a imputar los datos clasificados en la etapa anterior con las funciones de superficie, ambientes y precio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9793dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = imp_precio(imp_rooms(imp_superficie(dataClean,5),5),5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c969965f",
   "metadata": {},
   "source": [
    "[Subir](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d3a84d",
   "metadata": {},
   "source": [
    "<a name=\"impF\"></a>\n",
    "### 4.f. Aplicación de outliers\n",
    "##### *Se aplicó una función que elimina los valores outliers de precio por metro cuadrado agrupando por lugar y tipos de propiedades tomando como criterio el intervalo IQR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_ppsqm(data): \n",
    "    data = data.drop(columns= 'price_m2_calc_supTotal') \n",
    "    data['price_m2_calc_supTotal']= data['price_aprox_usd']/data['surface_total_in_m2_CLEAN']\n",
    "    \n",
    "    q1 = data.groupby(['place_name', 'property_type'])['price_m2_calc_supTotal'].quantile(0.25)\n",
    "    q2 = data.groupby(['place_name', 'property_type'])['price_m2_calc_supTotal'].quantile(0.5)\n",
    "    q3 = data.groupby(['place_name', 'property_type'])['price_m2_calc_supTotal'].quantile(0.75)\n",
    "    q4 = data.groupby(['place_name', 'property_type'])['price_m2_calc_supTotal'].quantile(1.)\n",
    "  \n",
    "    limite_sup = q3 + 1.5*(q3-q1)\n",
    "    \n",
    "    limite_inf = q1 - 1.5*(q3-q1)\n",
    "    \n",
    "    result=[]\n",
    "    prueba=data.loc[:,['place_name','property_type','price_m2_calc_supTotal']]\n",
    "    for i in range(len(prueba)):\n",
    "        try:\n",
    "            result.append((prueba.price_m2_calc_supTotal[i]<limite_sup[prueba.place_name[i], prueba.property_type[i]])&(prueba.price_m2_calc_supTotal[i]>limite_inf[prueba.place_name[i], prueba.property_type[i]]))\n",
    "        except:\n",
    "            result.append(False)\n",
    "    \n",
    "    mask = np.array(result)\n",
    "    print('Hay: ', (mask.shape-mask.sum())[0], 'outliers')\n",
    "\n",
    "    data = data[mask]\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    print('Nulos en place_name: ', data.place_name.isnull().sum())\n",
    "    print('Nulos en surface_total_in_m2_CLEAN: ', data.surface_total_in_m2_CLEAN.isnull().sum())\n",
    "    print('Nulos en price_aprox_usd: ', data.price_aprox_usd.isnull().sum())\n",
    "    print('Nulos en price_m2_calc_supTotal: ', data.price_m2_calc_supTotal.isnull().sum())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca175314",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = outliers_ppsqm(dataClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014828b3",
   "metadata": {},
   "source": [
    "[Subir](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2c751",
   "metadata": {},
   "source": [
    "<a name=\"impG\"></a>\n",
    "### 4.g. Imputación de las columnas latitud y longitud\n",
    "##### *Se decidió realizar la imputación de latitud y longitud, utilizando la mediana condicionada por los datos del lugar.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imp_lat_lon(data):\n",
    "    fill_values = data.groupby(['place_name']).lat.median().round(2)\n",
    "    fill_values_df = pd.DataFrame(fill_values)\n",
    "    fill_values_df.reset_index(inplace = True)\n",
    "\n",
    "    data_2 = data.merge(fill_values_df, on = ['place_name'], suffixes = (\"\", \"_median\"), how = 'left')\n",
    "    data_2.lat.fillna(data_2.lat_median, inplace = True)\n",
    "    data_2.drop('lat_median', axis=1, inplace=True)\n",
    "\n",
    "    fill_values = data.groupby(['place_name']).lon.median().round(2)\n",
    "    fill_values_df = pd.DataFrame(fill_values)\n",
    "    fill_values_df.reset_index(inplace = True)\n",
    "\n",
    "    data_2 = data_2.merge(fill_values_df, on = ['place_name'], suffixes = (\"\", \"_median\"), how = 'left')\n",
    "    data_2.lon.fillna(data_2.lon_median, inplace = True)\n",
    "    data_2.drop('lon_median', axis=1, inplace=True)\n",
    "    \n",
    "    print('Nulos en lat: ', data_2.lat.isnull().sum())\n",
    "    print('Nulos en lon: ', data_2.lon.isnull().sum())\n",
    "\n",
    "    return data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7527300",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = imp_lat_lon(dataClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5125e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_properati = gpd.GeoDataFrame(dataClean,geometry=gpd.points_from_xy(dataClean.lon, dataClean.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "geo_argentina = world[world.name=='Argentina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar(p_ciudad, p_pais):\n",
    "    \"\"\"Grafica ciudades sobre el mapa del pais\"\"\"\n",
    "    \n",
    "    ax = p_pais.plot(color='white', edgecolor='black')\n",
    "\n",
    "    # Sobre las ciudades superpone el mapa del país\n",
    "    p_ciudad.plot(ax=ax, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ddb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar(geo_properati,geo_argentina)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7290b4",
   "metadata": {},
   "source": [
    "[Subir](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22080e3",
   "metadata": {},
   "source": [
    "<a name=\"five\"></a>\n",
    "## 5. Análisis descriptivo, coeficientes de correlación entre precio y superficie.\n",
    "##### *Se calcularon los coeficientes de correlación para la información agrupada por place_name y property_type.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_pear(data, places, props, col1, col2):\n",
    "    #data: dataframe, place: array, prop: array, col1: string, col2: string (col1 y col2 serían las variables del coeficiente)\n",
    "    result=[]\n",
    "    for place in places:\n",
    "        for prop in props:\n",
    "            pearson = data[(data.property_type==prop)&(data.place_name==place)].corr(method='pearson')\n",
    "            result.append((place, prop, data.place_name[(data.property_type==prop)&(data.place_name==place)].count(), pearson.loc[col1, col2]))\n",
    "    result_data = pd.DataFrame(result, columns=['place_name', 'property_type', 'nr_of_properties', 'pearson'])\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se utiliza como muestra Capital Federal a modo de ejemplo. Se puede reemplazar por otro state_name.\n",
    "property_type = dataClean.property_type.unique()\n",
    "place_name = dataClean[dataClean.state_name=='Capital Federal'].place_name.unique()\n",
    "coef_dataClean = coef_pear(dataClean, place_name, property_type, 'surface_total_in_m2_CLEAN', 'price_aprox_usd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bae352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dataClean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821458d",
   "metadata": {},
   "source": [
    "##### *Se calcularon los coeficientes de correlación promedio según lugar(state_name y place_name), tipos de propiedades (excluyendo oversized) y, para que sea representativo, aquellos grupos que contienen mas de 20 propiedades.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c509c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dataClean[(coef_dataClean.property_type!='oversized')&(coef_dataClean['nr_of_properties']>20)].pearson.abs().mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9977149",
   "metadata": {},
   "source": [
    "[Subir](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c33d8d",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulos = pd.DataFrame(np.round(data.isnull().sum()*100/data.shape[0],2).sort_values(ascending=False), columns=['Porcentaje_de_nulos'])\n",
    "nulos = nulos[nulos.index!='Unnamed: 0']\n",
    "\n",
    "fig = plt.gcf()\n",
    "ax = plt.axes()\n",
    "\n",
    "fig.set_size_inches( 16, 10)\n",
    "ax.set(xlim=(0, 100))\n",
    "sns.barplot(x=\"Porcentaje_de_nulos\", y=nulos.index, data=nulos, palette= 'pastel')\n",
    "plt.title('Porcentaje de datos faltantes en el dataset inicial');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9098888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulos_finales = pd.DataFrame(np.round(dataClean.isnull().sum()*100/dataClean.shape[0],2).sort_values(ascending=False), columns=['Porcentaje_de_nulos'])\n",
    "nulos_finales = nulos_finales.drop(['surface_total_in_m2', 'surface_covered_in_m2'])\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches( 16, 10)\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set(xlim=(0, 100))\n",
    "sns.barplot(x=\"Porcentaje_de_nulos\", y=nulos_finales.index, data=nulos_finales, palette= 'pastel')\n",
    "plt.title('Porcentaje de datos faltantes en el dataset final');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_to_graph = dataClean[['place_name','state_name']].groupby(['state_name'])['place_name'] \\\n",
    "                .count() \\\n",
    "                .reset_index(name='count') \\\n",
    "                .sort_values(['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27182253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "fig = px.bar(data_frame = plot_to_graph.iloc[0:7], y='state_name',\n",
    "x='count', color = 'state_name',\n",
    "title = 'Distribución de propiedades por \\\"state_name\\\" (Top 7)', orientation = 'h')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4459b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_to_graph_1 = dataClean[['property_type']].groupby(['property_type'])['property_type'] \\\n",
    "                .count() \\\n",
    "                .reset_index(name='count') \\\n",
    "                .sort_values(['count'], ascending=False)\n",
    "\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "fig = px.bar(data_frame = plot_to_graph_1.iloc[0:6], y='property_type',\n",
    "x='count', color = 'property_type',\n",
    "title = 'Distribución de propiedades por tipo', orientation = 'h')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 10)\n",
    "\n",
    "sns.boxenplot(data=dataClean, y='price_m2_calc_supTotal', x='property_type');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataClean.to_excel('properati_final.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dhdsblend2021] *",
   "language": "python",
   "name": "conda-env-dhdsblend2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
